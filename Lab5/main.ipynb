{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd2fd3f3",
   "metadata": {},
   "source": [
    "# One-vs-Rest Classification with Oversampling on Iris Dataset\n",
    "This notebook demonstrates how to perform multi-class classification on the Iris dataset using a one-vs-rest approach. It includes manual oversampling and SMOTE-style oversampling to balance the classes, and compares results for different train/validation/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e32c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Results for 80-10-10 split ====\n",
      "Validation Accuracy: 0.80\n",
      "Test Accuracy: 0.80\n",
      "Classification Report (Test):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         5\n",
      "Iris-versicolor       0.75      0.60      0.67         5\n",
      " Iris-virginica       0.67      0.80      0.73         5\n",
      "\n",
      "       accuracy                           0.80        15\n",
      "      macro avg       0.81      0.80      0.80        15\n",
      "   weighted avg       0.81      0.80      0.80        15\n",
      "\n",
      "\n",
      "==== Results for 70-15-15 split ====\n",
      "Validation Accuracy: 0.68\n",
      "Test Accuracy: 0.83\n",
      "Classification Report (Test):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.83      0.62      0.71         8\n",
      " Iris-virginica       0.70      0.88      0.78         8\n",
      "\n",
      "       accuracy                           0.83        23\n",
      "      macro avg       0.84      0.83      0.83        23\n",
      "   weighted avg       0.84      0.83      0.82        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"Iris.csv\").drop(columns=[\"Id\"])\n",
    "X, y = df.drop(columns=[\"Species\"]), df[\"Species\"]\n",
    "classes = y.unique()\n",
    "\n",
    "# Split data into train/val/test\n",
    "def split_data(X, y, train_size, val_size, test_size):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, train_size=train_size, stratify=y, random_state=42\n",
    "    )\n",
    "    val_ratio = val_size / (val_size + test_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, train_size=val_ratio, stratify=y_temp, random_state=42\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Oversample binary labels to 100 positives and 100 negatives\n",
    "def oversample_fixed(X, y_binary, target_size=100):\n",
    "    def replicate_class(X_class):\n",
    "        reps = target_size // len(X_class)\n",
    "        remainder = target_size - reps * len(X_class)\n",
    "        replicated = pd.concat([X_class] * reps)\n",
    "        if remainder > 0:\n",
    "            replicated = pd.concat([replicated, X_class.sample(remainder, replace=True, random_state=42)])\n",
    "        return replicated\n",
    "\n",
    "    X_pos = X[y_binary == 1]\n",
    "    X_neg = X[y_binary == 0]\n",
    "    y_pos = pd.Series([1] * target_size)\n",
    "    y_neg = pd.Series([0] * target_size)\n",
    "\n",
    "    X_bal = pd.concat([replicate_class(X_pos), replicate_class(X_neg)])\n",
    "    y_bal = pd.concat([y_pos, y_neg])\n",
    "    return X_bal.to_numpy(), y_bal.to_numpy()\n",
    "\n",
    "# Predict using one-vs-rest models\n",
    "def predict(models, X):\n",
    "    prob_matrix = np.column_stack([model.predict(X) for model in models.values()])\n",
    "    return [cls for cls in classes[np.argmax(prob_matrix, axis=1)]]\n",
    "\n",
    "# Define splits\n",
    "splits = {\n",
    "    \"80-10-10\": split_data(X, y, 0.8, 0.1, 0.1),\n",
    "    \"70-15-15\": split_data(X, y, 0.7, 0.15, 0.15)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate models\n",
    "for split_name, (X_train, X_val, X_test, y_train, y_val, y_test) in splits.items():\n",
    "    print(f\"\\n==== Results for {split_name} split ====\")\n",
    "    models = {}\n",
    "\n",
    "    for cls in classes:\n",
    "        y_binary = (y_train == cls).astype(int)\n",
    "        X_resampled, y_resampled = oversample_fixed(X_train, y_binary)\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        models[cls] = model\n",
    "\n",
    "    y_val_pred = predict(models, X_val.to_numpy())\n",
    "    y_test_pred = predict(models, X_test.to_numpy())\n",
    "\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Validation Accuracy: {val_acc:.2f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "    print(\"Classification Report (Test):\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "    results[split_name] = {\"val_acc\": val_acc, \"test_acc\": test_acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7f3f0",
   "metadata": {},
   "source": [
    "## Data Loading, Preprocessing, and One-vs-Rest Training (Manual Oversampling)\n",
    "- Loads the Iris dataset and removes the 'Id' column.\n",
    "- Splits the data into train, validation, and test sets using stratified sampling.\n",
    "- Implements a function to manually oversample binary labels to a fixed number of positives and negatives.\n",
    "- Trains one-vs-rest linear regression models for each class using the oversampled data.\n",
    "- Evaluates the models on validation and test sets, reporting accuracy and classification metrics for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b96e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Results for 80-10-10 split ====\n",
      "\n",
      "[Fixed Oversampling]\n",
      "Validation Accuracy: 0.8\n",
      "Test Accuracy: 0.8\n",
      "Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         5\n",
      "Iris-versicolor       0.75      0.60      0.67         5\n",
      " Iris-virginica       0.67      0.80      0.73         5\n",
      "\n",
      "       accuracy                           0.80        15\n",
      "      macro avg       0.81      0.80      0.80        15\n",
      "   weighted avg       0.81      0.80      0.80        15\n",
      "\n",
      "\n",
      "[SMOTE-random]\n",
      "Validation Accuracy: 0.8\n",
      "Test Accuracy: 0.8\n",
      "Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         5\n",
      "Iris-versicolor       0.75      0.60      0.67         5\n",
      " Iris-virginica       0.67      0.80      0.73         5\n",
      "\n",
      "       accuracy                           0.80        15\n",
      "      macro avg       0.81      0.80      0.80        15\n",
      "   weighted avg       0.81      0.80      0.80        15\n",
      "\n",
      "\n",
      "[SMOTE-nearest]\n",
      "Validation Accuracy: 0.8\n",
      "Test Accuracy: 0.8\n",
      "Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         5\n",
      "Iris-versicolor       0.75      0.60      0.67         5\n",
      " Iris-virginica       0.67      0.80      0.73         5\n",
      "\n",
      "       accuracy                           0.80        15\n",
      "      macro avg       0.81      0.80      0.80        15\n",
      "   weighted avg       0.81      0.80      0.80        15\n",
      "\n",
      "\n",
      "==== Results for 70-15-15 split ====\n",
      "\n",
      "[Fixed Oversampling]\n",
      "Validation Accuracy: 0.6818181818181818\n",
      "Test Accuracy: 0.8260869565217391\n",
      "Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.83      0.62      0.71         8\n",
      " Iris-virginica       0.70      0.88      0.78         8\n",
      "\n",
      "       accuracy                           0.83        23\n",
      "      macro avg       0.84      0.83      0.83        23\n",
      "   weighted avg       0.84      0.83      0.82        23\n",
      "\n",
      "\n",
      "[SMOTE-random]\n",
      "Validation Accuracy: 0.6818181818181818\n",
      "Test Accuracy: 0.8260869565217391\n",
      "Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.83      0.62      0.71         8\n",
      " Iris-virginica       0.70      0.88      0.78         8\n",
      "\n",
      "       accuracy                           0.83        23\n",
      "      macro avg       0.84      0.83      0.83        23\n",
      "   weighted avg       0.84      0.83      0.82        23\n",
      "\n",
      "\n",
      "[SMOTE-nearest]\n",
      "Validation Accuracy: 0.6818181818181818\n",
      "Test Accuracy: 0.8260869565217391\n",
      "Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.83      0.62      0.71         8\n",
      " Iris-virginica       0.70      0.88      0.78         8\n",
      "\n",
      "       accuracy                           0.83        23\n",
      "      macro avg       0.84      0.83      0.83        23\n",
      "   weighted avg       0.84      0.83      0.82        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Iris.csv\").drop(columns=[\"Id\"])\n",
    "X, y = df.drop(columns=[\"Species\"]), df[\"Species\"]\n",
    "classes = y.unique()\n",
    "\n",
    "# === Data Splitting ===\n",
    "def split_data(X, y, train_size, val_size, test_size):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, train_size=train_size, stratify=y, random_state=42\n",
    "    )\n",
    "    val_ratio = val_size / (val_size + test_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, train_size=val_ratio, stratify=y_temp, random_state=42\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# === Fixed Oversampling (100:100) ===\n",
    "def oversample_fixed(X, y_binary, target_size=100):\n",
    "    def replicate_class(X_class):\n",
    "        reps = target_size // len(X_class)\n",
    "        remainder = target_size - reps * len(X_class)\n",
    "        replicated = pd.concat([X_class] * reps)\n",
    "        if remainder > 0:\n",
    "            replicated = pd.concat([replicated, X_class.sample(remainder, replace=True, random_state=42)])\n",
    "        return replicated\n",
    "\n",
    "    X_pos, X_neg = X[y_binary == 1], X[y_binary == 0]\n",
    "    y_pos = pd.Series([1] * target_size)\n",
    "    y_neg = pd.Series([0] * target_size)\n",
    "\n",
    "    X_bal = pd.concat([replicate_class(X_pos), replicate_class(X_neg)])\n",
    "    y_bal = pd.concat([y_pos, y_neg])\n",
    "    return X_bal.to_numpy(), y_bal.to_numpy()\n",
    "\n",
    "# === SMOTE-style Oversampling ===\n",
    "def smote_oversample(X, y, method=\"random\", lam=0.5):\n",
    "    X_min, X_maj = X[y == 1], X[y == 0]\n",
    "    target_size = len(X_maj)\n",
    "    synthetic = []\n",
    "\n",
    "    if method == \"random\":\n",
    "        while len(synthetic) + len(X_min) < target_size:\n",
    "            i, j = np.random.choice(len(X_min), 2, replace=False)\n",
    "            x_new = lam * X_min[i] + (1 - lam) * X_min[j]\n",
    "            synthetic.append(x_new)\n",
    "\n",
    "    elif method == \"nearest\":\n",
    "        neigh = NearestNeighbors(n_neighbors=2).fit(X_min)\n",
    "        while len(synthetic) + len(X_min) < target_size:\n",
    "            i = np.random.randint(len(X_min))\n",
    "            x1 = X_min[i]\n",
    "            _, idx = neigh.kneighbors([x1])\n",
    "            x2 = X_min[idx[0][1]]\n",
    "            x_new = lam * x1 + (1 - lam) * x2\n",
    "            synthetic.append(x_new)\n",
    "\n",
    "    X_syn = np.vstack([X_min, synthetic])\n",
    "    y_syn = np.ones(len(X_syn))\n",
    "    X_bal = np.vstack([X_syn, X_maj[:target_size]])\n",
    "    y_bal = np.hstack([y_syn, np.zeros(target_size)])\n",
    "    return X_bal, y_bal\n",
    "\n",
    "# === Prediction Function (One-vs-Rest) ===\n",
    "def predict(models, X):\n",
    "    prob_matrix = np.column_stack([model.predict(X) for model in models.values()])\n",
    "    return [cls for cls in classes[np.argmax(prob_matrix, axis=1)]]\n",
    "\n",
    "# === Define splits ===\n",
    "splits = {\n",
    "    \"80-10-10\": split_data(X, y, 0.8, 0.1, 0.1),\n",
    "    \"70-15-15\": split_data(X, y, 0.7, 0.15, 0.15)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# === Train and evaluate ===\n",
    "for split_name, (X_train, X_val, X_test, y_train, y_val, y_test) in splits.items():\n",
    "    print(f\"\\n==== Results for {split_name} split ====\")\n",
    "\n",
    "    # --- Fixed Oversampling ---\n",
    "    models = {}\n",
    "    for cls in classes:\n",
    "        y_binary = (y_train == cls).astype(int)\n",
    "        X_res, y_res = oversample_fixed(X_train, y_binary)\n",
    "        model = LinearRegression().fit(X_res, y_res)\n",
    "        models[cls] = model\n",
    "\n",
    "    y_val_pred = predict(models, X_val.to_numpy())\n",
    "    y_test_pred = predict(models, X_test.to_numpy())\n",
    "    print(\"\\n[Fixed Oversampling]\")\n",
    "    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(\"Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "    # --- SMOTE Oversampling (random & nearest) ---\n",
    "    for method in [\"random\", \"nearest\"]:\n",
    "        models = {}\n",
    "        for cls in classes:\n",
    "            y_binary = (y_train == cls).astype(int)\n",
    "            X_res, y_res = smote_oversample(X_train.to_numpy(), y_binary.to_numpy(), method=method)\n",
    "            model = LinearRegression().fit(X_res, y_res)\n",
    "            models[cls] = model\n",
    "\n",
    "        y_val_pred = predict(models, X_val.to_numpy())\n",
    "        y_test_pred = predict(models, X_test.to_numpy())\n",
    "        print(f\"\\n[SMOTE-{method}]\")\n",
    "        print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "        print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "        print(\"Report:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fe44d",
   "metadata": {},
   "source": [
    "## SMOTE-style Oversampling and Method Comparison\n",
    "- Loads the Iris dataset and splits it as before.\n",
    "- Implements manual oversampling and SMOTE-style oversampling (random and nearest neighbor methods) to balance classes.\n",
    "- Trains one-vs-rest linear regression models for each class using both oversampling strategies.\n",
    "- Compares validation and test accuracy for each method and split, and prints classification reports."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
